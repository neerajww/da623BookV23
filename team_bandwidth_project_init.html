
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Voice Analytics &#8212; DA623 Projects</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Singing voice separation" href="team_bug_smashers_project_init.html" />
    <link rel="prev" title="Project Plan Meet" href="project_plan_ppt.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo_da623.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DA623 Projects</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to DA623 Projects
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ideating.html">
   Ideation: Topics, utilities, and datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project_plan_ppt.html">
   Project Plan Meet
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Voice Analytics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_bug_smashers_project_init.html">
   Singing voice separation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_chiSquared_project_init.html">
   Rotating shaft analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_duality_project_init.html">
   COPD Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_error_404_project_init.html">
   Speaker Diarization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_gamma_project_init.html">
   Piano Music
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_hidden_layers_project_init.html">
   Gravitational Wave
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_ica_project_init.html">
   Epileptic Seizures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_pulse_project_init.html">
   Bird Sound Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_python_project_init.html">
   Emotion Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_rad_project_init.html">
   Signal Denoising
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_signalMinded_project_init.html">
   Accent Transfer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_symbiotes_project_init.html">
   Sound Visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_symphony_project_init.html">
   Beat Synchronization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="team_waveleds_project_init.html">
   Parkinson Diagnosis
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/team_bandwidth_project_init.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fteam_bandwidth_project_init.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#team-name">
   Team Name
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#team-members">
   Team Members
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#project-title">
   Project Title
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objective">
   Objective
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methodology">
   Methodology
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experiments-with-asr">
   Experiments with ASR
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deliverables">
   Deliverables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-to-be-used">
   Dataset to be used
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="voice-analytics">
<h1>Voice Analytics<a class="headerlink" href="#voice-analytics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="team-name">
<h2>Team Name<a class="headerlink" href="#team-name" title="Permalink to this headline">¶</a></h2>
<p>Bandwidth</p>
</div>
<div class="section" id="team-members">
<h2>Team Members<a class="headerlink" href="#team-members" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Suryansh Singh 190101089 CSE Bachelors</p></li>
<li><p>Anant Shankhdhar 190101011 CSE Bachelors</p></li>
<li><p>Yashwardhan Modi 190101101 CSE Bachelors</p></li>
</ul>
</div>
<div class="section" id="project-title">
<h2>Project Title<a class="headerlink" href="#project-title" title="Permalink to this headline">¶</a></h2>
<p>Voice Analytics Toolkit</p>
</div>
<div class="section" id="objective">
<h2>Objective<a class="headerlink" href="#objective" title="Permalink to this headline">¶</a></h2>
<p>The objective of this project is to explore the domain of machine learning and deep learning for the task of automatic speech recognition, this involves extracting features from speech data and then applying various deeplearning techniques to get the text out of speech data. We will also compare the performance, by varying sampling rate and bit rate of data. We will finally carry out sentiment analysis on the text obtained and provide an api for the same.</p>
</div>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>Automatic Speech Recognition (ASR) is a technology that enables machines to understand and interpret human speech. It uses algorithms to convert spoken language into written text, which can then be analyzed or used to perform a variety of tasks, such as controlling devices or responding to user requests.
Sentiment analysis, also known as opinion mining, is a subfield of natural language processing (NLP) that focuses on identifying and extracting subjective information from text. The goal of sentiment analysis is to determine the sentiment or emotion expressed in a piece of text, whether it’s positive, negative, or neutral.
Recent advancements in deep learning and neural networks have led to significant improvements in the accuracy and efficiency of sentiment analysis algorithms. Combined with ASR, sentiment analysis can be applied to analyze spoken language, providing valuable insights into customer sentiment and feedback in real-time.</p>
</div>
<div class="section" id="methodology">
<h2>Methodology<a class="headerlink" href="#methodology" title="Permalink to this headline">¶</a></h2>
<p>Automatic Speech Recognition: We plan on using DL models for speech recognition.</p>
<ul class="simple">
<li><p>DeepSpeech -  It is a multi layer BiLSTM model which utilizes the CTC loss. We will train the model on Common Voice Dataset made available by the   Mozilla Foundation.</p></li>
<li><p>Wav2Vec2 - It is the state of the art transformer based model released by Facebook. Pretrained model is available which can also be used</p></li>
</ul>
</div>
<div class="section" id="experiments-with-asr">
<h2>Experiments with ASR<a class="headerlink" href="#experiments-with-asr" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Evaluating performance of state-of-the-art ASR model with different:-</p>
<ul>
<li><p>Sampling Rates :- In speech recognition, sampling rate refers to the number of times per second that a speech signal is sampled and converted into a digital representation.</p></li>
<li><p>Bitrate :- Bitrate in speech recognition refers to the number of bits used to encode or represent each sample of a speech signal.</p></li>
</ul>
</li>
<li><p>Performance metrics:-</p>
<ul>
<li><p>Word Error Rate :-  the number of insertions, deletions, and substitutions for words made by the ASR system. (It deals in words)</p></li>
<li><p>Levenshtein Distance :- is a metric used to measure the difference between two strings of characters. It calculates the minimum number of insertions, deletions, and substitutions needed to transform one string into the other. (It deals in charaters)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="deliverables">
<h2>Deliverables<a class="headerlink" href="#deliverables" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>An .ipynb notebook containing a detailed analysis, graphs and comparison between models trained using different parametes.</p></li>
<li><p>A GitHub repository containing the source code and documentation of the project.</p></li>
<li><p>An oral presentation in class. * An spi that performs analysis of audio data on command</p></li>
</ul>
</div>
<div class="section" id="dataset-to-be-used">
<h2>Dataset to be used<a class="headerlink" href="#dataset-to-be-used" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Common Voice is a large, public dataset of voice recordings and their transcriptions, created and maintained by Mozilla, the non-profit organization behind the Firefox web browser. The dataset is intended to be used for research and development of Automatic Speech Recognition (ASR) systems.</p></li>
</ol>
<p>The Common Voice dataset includes recordings of people speaking in various languages, accents, and dialects. The recordings are collected through a web-based platform, where volunteers can contribute their voice by reading sentences aloud. The sentences are chosen at random from a collection of prompts, which ensures that the dataset is diverse and representative of different types of speech.</p>
<p>The dataset is available for 96 languages but we will use the English split.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, &amp; Michael Auli. (2020). wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations.</p></li>
<li><p>Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, &amp; Andrew Y. Ng. (2014). Deep Speech: Scaling up end-to-end speech recognition.</p></li>
<li><p>Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M. Tyers, &amp; Gregor Weber. (2020). Common Voice: A Massively-Multilingual Speech Corpus.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="project_plan_ppt.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Project Plan Meet</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="team_bug_smashers_project_init.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Singing voice separation</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Neeraj Sharma<br/>
        
            &copy; Copyright 2023.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>